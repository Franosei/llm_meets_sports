{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Franosei/llm_meets_sports/blob/main/codes/agentic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_5vf4UseQjSe"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "import tensorflow as tf\n",
        "\n",
        "# Custom Callback To Include in Callbacks List At Training Time\n",
        "class GarbageCollectorCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        gc.collect()"
      ],
      "metadata": {
        "id": "YzzqKrnsr6BZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ipykernel llama-index nest_asyncio llama-index-embeddings-huggingface llama-index-embeddings-instructor llama-index-llms-huggingface\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "dRSpFQXiBn4b"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import SimpleDirectoryReader"
      ],
      "metadata": {
        "id": "YEgkjlHTBB7n"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents = SimpleDirectoryReader(input_files=['/content/final_doc.pdf']).load_data()"
      ],
      "metadata": {
        "id": "HBmw3FThB9RE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "splitter = SentenceSplitter(chunk_size=500, chunk_overlap=200)\n",
        "nodes = splitter.get_nodes_from_documents(documents)"
      ],
      "metadata": {
        "id": "X4YLBvvFCyW0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "node_metadata = nodes[0].get_content(metadata_mode=True)\n",
        "print(node_metadata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1Wd0sLWBFmf",
        "outputId": "c4a2307f-ff84-44d3-90bf-f57ead83b3b4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page_label: 1\n",
            "file_name: final_doc.pdf\n",
            "file_path: /content/final_doc.pdf\n",
            "file_type: application/pdf\n",
            "file_size: 28772791\n",
            "creation_date: 2024-06-10\n",
            "last_modified_date: 2024-06-10\n",
            "\n",
            "information\n",
            "On 1994-01-19 00:00:00, Spain played against Portugal in Vigo, Spain. The match was a Friendly and was played on neutral\n",
            "ground. The home team Spain scored 2 goals, while the away team Portugal scored 2 goals. \n",
            "On 1994-02-09 00:00:00, Spain played against Poland in Santa Cruz de Tenerife, Spain. The match was a Friendly and was\n",
            "played on neutral ground. The home team Spain scored 1 goals, while the away team Poland scored 1 goals. \n",
            "On 1994-02-16 00:00:00, Italy played against France in Naples, Italy. The match was a Friendly and was played on neutral\n",
            "ground. The home team Italy scored 0 goals, while the away team France scored 1 goals. \n",
            "On 1994-02-23 00:00:00, Turkey played against Czech Republic in Istanbul, Turkey. The match was a Friendly and was played\n",
            "on neutral ground. The home team Turkey scored 1 goals, while the away team Czech Republic scored 4 goals. \n",
            "On 1994-03-09 00:00:00, England played against Denmark in London, England. The match was a Friendly and was played on\n",
            "neutral ground. The home team England scored 1 goals, while the away team Denmark scored 0 goals. \n",
            "On 1994-03-09 00:00:00, Hungary played against Switzerland in Budapest, Hungary. The match was a Friendly and was played\n",
            "on neutral ground. The home team Hungary scored 1 goals, while the away team Switzerland scored 2 goals. \n",
            "On 1994-03-23 00:00:00, Austria played against Hungary in Linz, Austria. The match was a Friendly and was played on neutral\n",
            "ground. The home team Austria scored 1 goals, while the away team Hungary scored 1 goals. \n",
            "On 1994-03-23 00:00:00, Germany played against Italy in Stuttgart, Germany. The match was a Friendly and was played on\n",
            "neutral ground. The home team Germany scored 2 goals, while the away team Italy scored 1 goals.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from typing import List, Optional\n",
        "from llama_index.llms.huggingface import (\n",
        "    HuggingFaceInferenceAPI,\n",
        "    HuggingFaceLLM,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKLuh_N4C68g",
        "outputId": "28399d21-ea82-44d2-bec2-84d6f7583ac4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:160: UserWarning: Field \"model_id\" has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "HF_TOKEN: Optional[str] = os.getenv(\"HUGGING_FACE_TOKEN\")"
      ],
      "metadata": {
        "id": "zhWNWa52C-Lf"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import Settings\n",
        "from llama_index.llms.huggingface import HuggingFaceLLM\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding"
      ],
      "metadata": {
        "id": "dWW4MeCYDR10"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sZErkyrFxGqg"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Settings.llm = HuggingFaceLLM(model_name=\"mistralai/Mistral-7B-v0.1\")\n",
        "Settings.embed_model = HuggingFaceEmbedding(model_name=\"allenai/longformer-base-4096\")\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "O-jJqQccDUea"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import SummaryIndex, VectorStoreIndex\n",
        "summary_index = SummaryIndex(nodes)\n",
        "vector_index = VectorStoreIndex(nodes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbBuVqQ3DYrn",
        "outputId": "f4380910-ba8d-4d02-8612-490cb4b043a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Input ids are automatically padded to be a multiple of `config.attention_window`: 512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary_query_engine = summary_index.as_query_engine(\n",
        "    response_mode = \"tree_summarize\",\n",
        "    use_async = True\n",
        ")\n",
        "\n",
        "vector_query_engine = vector_index.as_query_engine()"
      ],
      "metadata": {
        "id": "xSF0bubcDb2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.tools import QueryEngineTool\n",
        "\n",
        "\n",
        "summary_tool = QueryEngineTool.from_defaults(\n",
        "    query_engine=summary_query_engine,\n",
        "    description=(\n",
        "        \"Useful for summarization questions related to the documnet.\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "vector_tool = QueryEngineTool.from_defaults(\n",
        "    query_engine=vector_query_engine,\n",
        "    description=(\n",
        "        \"Useful for analysis the the probability of each team wining and the expected number of goals.\"\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "id": "tqZGekiQDvnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.query_engine.router_query_engine import RouterQueryEngine\n",
        "from llama_index.core.selectors import LLMSingleSelector\n",
        "\n",
        "\n",
        "query_engine = RouterQueryEngine(\n",
        "    selector=LLMSingleSelector.from_defaults(),\n",
        "    query_engine_tools=[\n",
        "        summary_tool,\n",
        "        vector_tool,\n",
        "    ],\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "5jMnFzYoD1xU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    response = query_engine.query(\"What is Francis doing\")\n",
        "    print(str(response))\n",
        "except Exception as e:\n",
        "    print(\"An error occurred:\", str(e))\n"
      ],
      "metadata": {
        "id": "zX7hbHYXD7xC"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}